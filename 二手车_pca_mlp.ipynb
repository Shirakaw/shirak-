{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b16550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression mlp model for the abalone dataset\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8105f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('ave.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd23e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=150)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = RandomizedPCA(150)\n",
    "pca.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ae4227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ca1c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "X = train_data.drop(['carid', 'price'], axis=1)\n",
    "y = train_data['carid']\n",
    "n_components = 150\n",
    "pca = PCA(n_components=n_components, svd_solver=\"randomized\", whiten=True).fit(X)\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6f7d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00fbd0aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "629/629 - 1s - loss: 1572890752.0000\n",
      "Epoch 2/150\n",
      "629/629 - 1s - loss: 554061056.0000\n",
      "Epoch 3/150\n",
      "629/629 - 1s - loss: 456282688.0000\n",
      "Epoch 4/150\n",
      "629/629 - 1s - loss: 455033664.0000\n",
      "Epoch 5/150\n",
      "629/629 - 1s - loss: 453810400.0000\n",
      "Epoch 6/150\n",
      "629/629 - 1s - loss: 452575104.0000\n",
      "Epoch 7/150\n",
      "629/629 - 1s - loss: 451370240.0000\n",
      "Epoch 8/150\n",
      "629/629 - 1s - loss: 450359072.0000\n",
      "Epoch 9/150\n",
      "629/629 - 1s - loss: 449266880.0000\n",
      "Epoch 10/150\n",
      "629/629 - 1s - loss: 448186432.0000\n",
      "Epoch 11/150\n",
      "629/629 - 1s - loss: 447152096.0000\n",
      "Epoch 12/150\n",
      "629/629 - 1s - loss: 446157984.0000\n",
      "Epoch 13/150\n",
      "629/629 - 1s - loss: 445067296.0000\n",
      "Epoch 14/150\n",
      "629/629 - 1s - loss: 444076256.0000\n",
      "Epoch 15/150\n",
      "629/629 - 1s - loss: 443002176.0000\n",
      "Epoch 16/150\n",
      "629/629 - 1s - loss: 441971712.0000\n",
      "Epoch 17/150\n",
      "629/629 - 1s - loss: 440825888.0000\n",
      "Epoch 18/150\n",
      "629/629 - 1s - loss: 439649696.0000\n",
      "Epoch 19/150\n",
      "629/629 - 1s - loss: 438511104.0000\n",
      "Epoch 20/150\n",
      "629/629 - 1s - loss: 437191040.0000\n",
      "Epoch 21/150\n",
      "629/629 - 1s - loss: 436085504.0000\n",
      "Epoch 22/150\n",
      "629/629 - 1s - loss: 434665152.0000\n",
      "Epoch 23/150\n",
      "629/629 - 1s - loss: 433264768.0000\n",
      "Epoch 24/150\n",
      "629/629 - 1s - loss: 431785376.0000\n",
      "Epoch 25/150\n",
      "629/629 - 1s - loss: 430217728.0000\n",
      "Epoch 26/150\n",
      "629/629 - 1s - loss: 428616736.0000\n",
      "Epoch 27/150\n",
      "629/629 - 1s - loss: 426738464.0000\n",
      "Epoch 28/150\n",
      "629/629 - 1s - loss: 424877920.0000\n",
      "Epoch 29/150\n",
      "629/629 - 1s - loss: 422921856.0000\n",
      "Epoch 30/150\n",
      "629/629 - 1s - loss: 420591648.0000\n",
      "Epoch 31/150\n",
      "629/629 - 1s - loss: 418226432.0000\n",
      "Epoch 32/150\n",
      "629/629 - 1s - loss: 415676768.0000\n",
      "Epoch 33/150\n",
      "629/629 - 1s - loss: 412852896.0000\n",
      "Epoch 34/150\n",
      "629/629 - 1s - loss: 409843808.0000\n",
      "Epoch 35/150\n",
      "629/629 - 1s - loss: 406507872.0000\n",
      "Epoch 36/150\n",
      "629/629 - 1s - loss: 402699104.0000\n",
      "Epoch 37/150\n",
      "629/629 - 1s - loss: 398594400.0000\n",
      "Epoch 38/150\n",
      "629/629 - 1s - loss: 394020640.0000\n",
      "Epoch 39/150\n",
      "629/629 - 1s - loss: 389005792.0000\n",
      "Epoch 40/150\n",
      "629/629 - 1s - loss: 383447072.0000\n",
      "Epoch 41/150\n",
      "629/629 - 1s - loss: 377340128.0000\n",
      "Epoch 42/150\n",
      "629/629 - 1s - loss: 370590176.0000\n",
      "Epoch 43/150\n",
      "629/629 - 1s - loss: 363322496.0000\n",
      "Epoch 44/150\n",
      "629/629 - 1s - loss: 355357152.0000\n",
      "Epoch 45/150\n",
      "629/629 - 1s - loss: 346956416.0000\n",
      "Epoch 46/150\n",
      "629/629 - 1s - loss: 338155968.0000\n",
      "Epoch 47/150\n",
      "629/629 - 1s - loss: 329380608.0000\n",
      "Epoch 48/150\n",
      "629/629 - 1s - loss: 320808864.0000\n",
      "Epoch 49/150\n",
      "629/629 - 1s - loss: 312662112.0000\n",
      "Epoch 50/150\n",
      "629/629 - 1s - loss: 305439904.0000\n",
      "Epoch 51/150\n",
      "629/629 - 1s - loss: 299478624.0000\n",
      "Epoch 52/150\n",
      "629/629 - 1s - loss: 294760192.0000\n",
      "Epoch 53/150\n",
      "629/629 - 1s - loss: 291358688.0000\n",
      "Epoch 54/150\n",
      "629/629 - 1s - loss: 288855456.0000\n",
      "Epoch 55/150\n",
      "629/629 - 1s - loss: 287318720.0000\n",
      "Epoch 56/150\n",
      "629/629 - 1s - loss: 286143872.0000\n",
      "Epoch 57/150\n",
      "629/629 - 1s - loss: 285411744.0000\n",
      "Epoch 58/150\n",
      "629/629 - 1s - loss: 284667488.0000\n",
      "Epoch 59/150\n",
      "629/629 - 1s - loss: 284245120.0000\n",
      "Epoch 60/150\n",
      "629/629 - 1s - loss: 283972288.0000\n",
      "Epoch 61/150\n",
      "629/629 - 1s - loss: 283750368.0000\n",
      "Epoch 62/150\n",
      "629/629 - 1s - loss: 283407648.0000\n",
      "Epoch 63/150\n",
      "629/629 - 1s - loss: 282987488.0000\n",
      "Epoch 64/150\n",
      "629/629 - 1s - loss: 282977248.0000\n",
      "Epoch 65/150\n",
      "629/629 - 1s - loss: 282902976.0000\n",
      "Epoch 66/150\n",
      "629/629 - 1s - loss: 282490848.0000\n",
      "Epoch 67/150\n",
      "629/629 - 1s - loss: 282365024.0000\n",
      "Epoch 68/150\n",
      "629/629 - 1s - loss: 282380480.0000\n",
      "Epoch 69/150\n",
      "629/629 - 1s - loss: 282206176.0000\n",
      "Epoch 70/150\n",
      "629/629 - 1s - loss: 282099744.0000\n",
      "Epoch 71/150\n",
      "629/629 - 1s - loss: 281887808.0000\n",
      "Epoch 72/150\n",
      "629/629 - 1s - loss: 282004384.0000\n",
      "Epoch 73/150\n",
      "629/629 - 1s - loss: 281875392.0000\n",
      "Epoch 74/150\n",
      "629/629 - 1s - loss: 281758176.0000\n",
      "Epoch 75/150\n",
      "629/629 - 1s - loss: 281869344.0000\n",
      "Epoch 76/150\n",
      "629/629 - 1s - loss: 281590144.0000\n",
      "Epoch 77/150\n",
      "629/629 - 1s - loss: 281684480.0000\n",
      "Epoch 78/150\n",
      "629/629 - 1s - loss: 281834944.0000\n",
      "Epoch 79/150\n",
      "629/629 - 1s - loss: 281492416.0000\n",
      "Epoch 80/150\n",
      "629/629 - 1s - loss: 281701376.0000\n",
      "Epoch 81/150\n",
      "629/629 - 1s - loss: 281541088.0000\n",
      "Epoch 82/150\n",
      "629/629 - 1s - loss: 281490144.0000\n",
      "Epoch 83/150\n",
      "629/629 - 1s - loss: 281452000.0000\n",
      "Epoch 84/150\n",
      "629/629 - 1s - loss: 281414336.0000\n",
      "Epoch 85/150\n",
      "629/629 - 1s - loss: 281453728.0000\n",
      "Epoch 86/150\n",
      "629/629 - 1s - loss: 281462432.0000\n",
      "Epoch 87/150\n",
      "629/629 - 1s - loss: 281370016.0000\n",
      "Epoch 88/150\n",
      "629/629 - 1s - loss: 281266176.0000\n",
      "Epoch 89/150\n",
      "629/629 - 1s - loss: 281391776.0000\n",
      "Epoch 90/150\n",
      "629/629 - 1s - loss: 281336704.0000\n",
      "Epoch 91/150\n",
      "629/629 - 1s - loss: 281415392.0000\n",
      "Epoch 92/150\n",
      "629/629 - 1s - loss: 281180448.0000\n",
      "Epoch 93/150\n",
      "629/629 - 1s - loss: 281351968.0000\n",
      "Epoch 94/150\n",
      "629/629 - 1s - loss: 281141984.0000\n",
      "Epoch 95/150\n",
      "629/629 - 1s - loss: 281256896.0000\n",
      "Epoch 96/150\n",
      "629/629 - 1s - loss: 281365408.0000\n",
      "Epoch 97/150\n",
      "629/629 - 1s - loss: 281407840.0000\n",
      "Epoch 98/150\n",
      "629/629 - 1s - loss: 281254496.0000\n",
      "Epoch 99/150\n",
      "629/629 - 1s - loss: 281363776.0000\n",
      "Epoch 100/150\n",
      "629/629 - 1s - loss: 281370048.0000\n",
      "Epoch 101/150\n",
      "629/629 - 1s - loss: 281190016.0000\n",
      "Epoch 102/150\n",
      "629/629 - 1s - loss: 281228224.0000\n",
      "Epoch 103/150\n",
      "629/629 - 1s - loss: 281207584.0000\n",
      "Epoch 104/150\n",
      "629/629 - 1s - loss: 281116928.0000\n",
      "Epoch 105/150\n",
      "629/629 - 1s - loss: 281216864.0000\n",
      "Epoch 106/150\n",
      "629/629 - 1s - loss: 281130880.0000\n",
      "Epoch 107/150\n",
      "629/629 - 1s - loss: 281128448.0000\n",
      "Epoch 108/150\n",
      "629/629 - 1s - loss: 281133920.0000\n",
      "Epoch 109/150\n",
      "629/629 - 1s - loss: 281314336.0000\n",
      "Epoch 110/150\n",
      "629/629 - 1s - loss: 281059488.0000\n",
      "Epoch 111/150\n",
      "629/629 - 1s - loss: 281095904.0000\n",
      "Epoch 112/150\n",
      "629/629 - 1s - loss: 281155712.0000\n",
      "Epoch 113/150\n",
      "629/629 - 1s - loss: 281112576.0000\n",
      "Epoch 114/150\n",
      "629/629 - 1s - loss: 281158464.0000\n",
      "Epoch 115/150\n",
      "629/629 - 1s - loss: 281209760.0000\n",
      "Epoch 116/150\n",
      "629/629 - 1s - loss: 281061248.0000\n",
      "Epoch 117/150\n",
      "629/629 - 1s - loss: 281117536.0000\n",
      "Epoch 118/150\n",
      "629/629 - 1s - loss: 281170240.0000\n",
      "Epoch 119/150\n",
      "629/629 - 1s - loss: 281132000.0000\n",
      "Epoch 120/150\n",
      "629/629 - 1s - loss: 281091552.0000\n",
      "Epoch 121/150\n",
      "629/629 - 1s - loss: 281032512.0000\n",
      "Epoch 122/150\n",
      "629/629 - 1s - loss: 281086496.0000\n",
      "Epoch 123/150\n",
      "629/629 - 1s - loss: 281033280.0000\n",
      "Epoch 124/150\n",
      "629/629 - 1s - loss: 281041280.0000\n",
      "Epoch 125/150\n",
      "629/629 - 1s - loss: 279936416.0000\n",
      "Epoch 126/150\n",
      "629/629 - 1s - loss: 275904576.0000\n",
      "Epoch 127/150\n",
      "629/629 - 1s - loss: 273973888.0000\n",
      "Epoch 128/150\n",
      "629/629 - 1s - loss: 272784928.0000\n",
      "Epoch 129/150\n",
      "629/629 - 1s - loss: 271784096.0000\n",
      "Epoch 130/150\n",
      "629/629 - 1s - loss: 270909248.0000\n",
      "Epoch 131/150\n",
      "629/629 - 1s - loss: 269839552.0000\n",
      "Epoch 132/150\n",
      "629/629 - 1s - loss: 269050272.0000\n",
      "Epoch 133/150\n",
      "629/629 - 1s - loss: 268103296.0000\n",
      "Epoch 134/150\n",
      "629/629 - 1s - loss: 267066224.0000\n",
      "Epoch 135/150\n",
      "629/629 - 1s - loss: 266066400.0000\n",
      "Epoch 136/150\n",
      "629/629 - 1s - loss: 265100048.0000\n",
      "Epoch 137/150\n",
      "629/629 - 1s - loss: 264149680.0000\n",
      "Epoch 138/150\n",
      "629/629 - 1s - loss: 262943136.0000\n",
      "Epoch 139/150\n",
      "629/629 - 1s - loss: 262025088.0000\n",
      "Epoch 140/150\n",
      "629/629 - 1s - loss: 260934880.0000\n",
      "Epoch 141/150\n",
      "629/629 - 1s - loss: 259771872.0000\n",
      "Epoch 142/150\n",
      "629/629 - 1s - loss: 258678672.0000\n",
      "Epoch 143/150\n",
      "629/629 - 1s - loss: 257637776.0000\n",
      "Epoch 144/150\n",
      "629/629 - 1s - loss: 256384208.0000\n",
      "Epoch 145/150\n",
      "629/629 - 1s - loss: 255396416.0000\n",
      "Epoch 146/150\n",
      "629/629 - 1s - loss: 254039184.0000\n",
      "Epoch 147/150\n",
      "629/629 - 1s - loss: 252877008.0000\n",
      "Epoch 148/150\n",
      "629/629 - 1s - loss: 251712320.0000\n",
      "Epoch 149/150\n",
      "629/629 - 1s - loss: 250490192.0000\n",
      "Epoch 150/150\n",
      "629/629 - 1s - loss: 249177216.0000\n",
      "MAE: 11484.147\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2)\n",
    "# evaluate on test set\n",
    "yhat = model.predict(X_test)\n",
    "error = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37229acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(331, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(layers.Dense(1000, activation='relu'))\n",
    "    model.add(layers.Dense(1))  # 线性\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca984713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_13_input to have shape (331,) but got array with shape (150,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24620/3104554585.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1,\n\u001b[1;32m---> 21\u001b[1;33m               verbose=0)  # 训练模型（静默模式，vervose=0）\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mval_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 在验证数据上评估模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mall_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_mae\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\12499\\anaconda3\\envs\\sci\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\12499\\anaconda3\\envs\\sci\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\12499\\anaconda3\\envs\\sci\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_13_input to have shape (331,) but got array with shape (150,)"
     ]
    }
   ],
   "source": [
    "# k折验证\n",
    "k = 4\n",
    "num_val_samples = len(X_pca) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data =X_pca[i * num_val_samples: (i + 1) * num_val_samples]  # 准备验证数据：第k个分区的数据\n",
    "    val_targets = y[i * num_val_samples:(i + 1) * num_val_samples]\n",
    "    # 准备训练数据：其他所有分区的数据\n",
    "    partial_train_data = np.concatenate(\n",
    "        [X_pca[:i * num_val_samples],\n",
    "        X_pca[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [y[:i * num_val_samples],\n",
    "         y[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1,\n",
    "              verbose=0)  # 训练模型（静默模式，vervose=0）\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)  # 在验证数据上评估模型\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500 \n",
    "all_mae_histories = [] \n",
    "for i in range(k):\n",
    "     print('processing fold #', i)\n",
    "     val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples] \n",
    "     val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "     partial_train_data = np.concatenate( [train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]], axis=0)\n",
    "     partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],train_targets[(i + 1) * num_val_samples:]],axis=0)\n",
    "     model = build_model() \n",
    "     history = model.fit(partial_train_data, partial_train_targets, \n",
    "     validation_data=(val_data, val_targets),epochs=num_epochs, batch_size=1, verbose=0)\n",
    "     mae_history = history.history['val_mean_absolute_error']\n",
    "     all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4a919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
